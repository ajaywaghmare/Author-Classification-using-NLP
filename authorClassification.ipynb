{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "URLs = ['https://www.gutenberg.org/files/580/580-0.txt', \n",
    "        'https://www.gutenberg.org/cache/epub/946/pg946.txt', \n",
    "        'https://www.gutenberg.org/cache/epub/139/pg139.txt', \n",
    "        'https://www.gutenberg.org/cache/epub/2165/pg2165.txt', \n",
    "        'https://www.gutenberg.org/files/65317/65317-0.txt']\n",
    "\n",
    "dict1 = {}\n",
    "i = 0\n",
    "for url in URLs :\n",
    "    with urllib.request.urlopen(url) as url:\n",
    "        s = url.read().splitlines()\n",
    "        dict1[i] = s\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for k,v in dict1.items():\n",
    "    list1 = []\n",
    "    for i in v :\n",
    "        list1.append(i.decode('UTF-8-sig'))\n",
    "        \n",
    "    dict1[k] = list1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for k,v in dict1.items():\n",
    "    list1 = []\n",
    "    for i in v :\n",
    "        if i is '' :\n",
    "            v.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dict1.items():\n",
    "    del(v[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list1:\n",
    "    if i is '' :\n",
    "        list1.remove(i)\n",
    "        \n",
    "del(list1[:500])\n",
    "# list2.append(' '.join(list1))\n",
    "# str1 = ''\n",
    "# str1 = list2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308684\n",
      "20815\n",
      "75186\n",
      "15017\n",
      "131613\n"
     ]
    }
   ],
   "source": [
    "# Tokanizing the text\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "\n",
    "for k,v in dict1.items():\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    dict1[k] = tokenizer.tokenize(str(v))\n",
    "    print(len(dict1[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308684"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Tokanizing the text\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# temp_list1 = tokenizer.tokenize(str1)\n",
    "# len(temp_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308684\n",
      "20815\n",
      "75186\n",
      "15017\n",
      "131613\n"
     ]
    }
   ],
   "source": [
    "# convert to lowercase\n",
    "for k,v in dict1.items():\n",
    "    dict1[k] = [t.lower() for t in v]\n",
    "    print(len(dict1[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308684"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # convert to lowercase\n",
    "# lower_tokens = [t.lower() for t in temp_list1]\n",
    "# len(lower_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308180\n",
      "20710\n",
      "75072\n",
      "14894\n",
      "130594\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuations\n",
    "for k,v in dict1.items():\n",
    "    dict1[k] = [t for t in v if t.isalpha()]\n",
    "    print(len(dict1[k]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308180"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Remove punctuations\n",
    "# alpha_only = [t for t in lower_tokens if t.isalpha()]\n",
    "# len(alpha_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "for k,v in dict1.items():\n",
    "    dict1[k] = [t for t in v if t not in stopwords.words('english')]\n",
    "    print(len(dict1[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove stopwords\n",
    "# from nltk.corpus import stopwords\n",
    "# no_stops = [t for t in alpha_only if t not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157373"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [no_stops[i:i + 50] for i in range(0, len(no_stops), 50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3148"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del(records[1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
